{
  "Tokenizer": {
    "$comment": "config of Tokenizer. vocab_size, src_tokenizer_regex, tgt_tokenizer_regex are required",
    "type": "BPE",
    "load": {
      "$comment": "key value is for load tokenizer from local file or train a new one. key dir is the directory to load tokenizer from or save tokenizer to ",
      "value": true,
      "dir": "./"
    },
    "all_chars": [32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,124,160,167,169,8208,8209,8211,8212,8216,8217,8220,8221,8224,8225,8230,8240,8242,8243,8364,171,178,179,187,192,194,198,199,200,201,202,203,206,207,212,217,219,220,224,226,230,231,232,233,234,235,238,239,244,249,251,252,255,338,339,376,691,738,7496,7497,8239,8722],
    "src_tokenizer_regex": "\\d+(?:[\\.,]\\d+)* | \\w+(?:[-']\\w+)* | \\S\\S+ | \\S",
    "tgt_tokenizer_regex": "\\d+(?:[\\.,]\\d+)* | [a-zA-ZàâäéèêëîïôöùûüçÀÂÄÉÈÊËÎÏÔÖÙÛÜÇ]['’] | [a-zA-ZÀÂÆÇÈÉÊËÎÏÔÙÛÜàâæçèéêëîïôùûüÿŒœŸ]+(?:[-'’][a-zA-ZÀÂÆÇÈÉÊËÎÏÔÙÛÜàâæçèéêëîïôùûüÿŒœŸ]+)* | \\S\\S+ | \\S",
    "vocab_size": 30000,
    "special_tokens": ["<PAD>", "<BOS>", "<EOS>"],
    "sample_size": 0.2
  },
  "Dataloader": {
    "$comment": "config of Dataloader. data_path is required",
    "data_path": ".\\data\\en-fr.csv",
    "allowed_chars": [32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,124,160,167,169,8208,8209,8211,8212,8216,8217,8220,8221,8224,8225,8230,8240,8242,8243,8364,171,178,179,187,192,194,198,199,200,201,202,203,206,207,212,217,219,220,224,226,230,231,232,233,234,235,238,239,244,249,251,252,255,338,339,376,691,738,7496,7497,8239,8722],
    "nrows": 5000000
  },
  "Trainer": {
    "$comment": "config of Trainer. model, num_epoch are required.",
    "num_epoch": 10,
    "dataloader": {
      "type": "get_transformer_dataloader",
      "params": {
        "max_seq_len": 100,
        "batch_size": 32,
        "train_val_test_split": [0.7, 0.15, 0.15]
      }
    },
    "save_period": {
      "value": 5000,
      "description": "save checkpoint every 5000 batch"
    },
    "resume": {
      "value": true,
      "ckpt_dir": "./checkpoints/transformer/2025_7_27/",
      "description": "when value=true, ckpt_dir is required. an example of ckpt_dir: ./checkpoints/transformer/<folder_name>/"
    },
    "model": {
      "type": "Transformer",
      "params": {
        "embed_dim": 512,
        "num_layers": 6,
        "num_heads": 8,
        "feedforward_dim": 2048,
        "num_tokens": 30000,
        "pad_token_id": 0
      }
    },
    "optimizer": {
      "type": "AdamW",
      "params": {
        "betas": [0.9, 0.98],
        "eps": 1e-09,
        "weight_decay": 1e-2
      }
    },
    "lr_scheduler": {
      "type": "LambdaLR",
      "lambda": {
        "type": "Transformer_lambda",
        "params": {
          "embed_dim": 512,
          "warmup_steps": 4000
        }
      }
    },
    "criterion": {
      "type": "CrossEntropyLoss",
      "params": {
        "ignore_index": 0,
        "label_smoothing": 0.1
      }
    }
  },
  "Evaluator":{
    "model": {
      "type": "Transformer",
      "params": {
        "embed_dim": 512,
        "num_layers": 6,
        "num_heads": 8,
        "feedforward_dim": 2048,
        "num_tokens": 30000,
        "pad_token_id": 0
      }
    },
    "reversed_tokens_dir": "./",
    "ckpt_dir": "./checkpoints/transformer/<folder_name>/"
  }
}