{
  "Tokenizer": {
    "$comment": "config of Tokenizer. vocab_size, src_tokenizer_regex, tgt_tokenizer_regex are required",
    "type": "WordPiece",
    "load": {
      "$comment": "key value is for load tokenizer from local file or train a new one. key dir is the directory to load tokenizer from or save tokenizer to ",
      "value": true,
      "dir": "./trained_tokenizer/BERT"
    },
    "all_chars": [32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,124,160,167,169,8208,8209,8211,8212,8216,8217,8220,8221,8224,8225,8230,8240,8242,8243,8364],
    "src_tokenizer_regex": "\\w+(?:[-']\\w+)* | \\d+ | \\S\\S+ | \\S",
    "tgt_tokenizer_regex": "\\w+(?:[-']\\w+)* | \\d+ | \\S\\S+ | \\S",
    "vocab_size": 30000,
    "special_tokens": ["<PAD>", "<MASK>", "<CLS>", "<SEP>", "<UNK>"],
    "sample_size": 0.2
  },
  "Dataloader": {
    "$comment": "config of Dataloader. data_path is required",
    "data_file": "./data/test.parquet",
    "allowed_chars": ""
  },
  "Trainer": {
    "$comment": "config of Trainer. model, num_epoch are required.",
    "type": "BERTTrainer",
    "num_epoch": 10,
    "max_num_ckpt": -1,
    "dataloader": {
      "type": "get_bert_dataloader",
      "params": {
        "max_seq_len": 100,
        "batch_size": 32,
        "num_workers": 8,
        "pin_memory": true,
        "random_token_start": 5,
        "random_token_end": 28211,
        "pad_token_id": 0,
        "mask_token_id": 1,
        "cls_token_id": 2,
        "sep_token_id": 3,
        "train_val_test_split": [0.7, 0.15, 0.15]
      }
    },
    "save_period": {
      "value": 5000,
      "description": "save checkpoint every 5000 batch"
    },
    "resume": {
      "value": true,
      "ckpt_dir": "./checkpoints/bert/2025_8_29_23_6_20/",
      "description": "when value=true, ckpt_dir is required. an example of ckpt_dir: ./checkpoints/transformer/<folder_name>/"
    },
    "model": {
      "type": "BERT",
      "params": {
        "embed_dim": 512,
        "num_layers": 6,
        "num_heads": 8,
        "feedforward_dim": 2048,
        "pad_token_id": 0,
        "dropout": 0.1
      }
    },
    "optimizer": {
      "type": "AdamW",
      "params": {
        "betas": [0.9, 0.98],
        "eps": 1e-09,
        "weight_decay": 1e-2
      }
    },
    "lr_scheduler": {
      "type": "LambdaLR",
      "lambda": {
        "type": "Transformer_lambda",
        "params": {
          "embed_dim": 512,
          "warmup_steps": 4000
        }
      }
    },
    "criterion": {
      "type": "CrossEntropyLoss",
      "params": {
        "ignore_index": 0,
        "label_smoothing": 0.1
      }
    }
  },
  "Evaluator":{
    "model": {
      "type": "Transformer",
      "params": {
        "embed_dim": 512,
        "num_layers": 6,
        "num_heads": 8,
        "feedforward_dim": 2048,
        "num_tokens": 30000,
        "pad_token_id": 0
      }
    },
    "reversed_tokens_dir": "./",
    "ckpt_dir": "./checkpoints/transformer/<folder_name>/"
  }
}